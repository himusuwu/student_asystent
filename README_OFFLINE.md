# ğŸ“š Student Assistant v2.3 - OFFLINE MODE

> **PeÅ‚na funkcjonalnoÅ›Ä‡ offline z Qwen 2.5:14b!**

## ğŸš€ Szybki start (1 komenda)

```bash
npm run start:offline
```

System automatycznie uruchomi:
- âœ… Ollama + Qwen 2.5:14b (AI offline)
- âœ… Backend (transkrypcja + dokumenty)
- âœ… Frontend (interfejs)

**OtwÃ³rz:** http://localhost:8000

---

## âœ¨ Co dziaÅ‚a offline?

| Funkcja | Status | Czas |
|---------|--------|------|
| ğŸ¤ Transkrypcja audio (Whisper) | âœ… Offline | 2-5 min |
| ğŸ“„ Ekstrakcja PDF | âœ… Offline | 10-30 sek |
| ğŸ“Š Ekstrakcja PowerPoint | âœ… Offline (backend) | 10-30 sek |
| ğŸ¤– Generowanie tytuÅ‚Ã³w (Qwen) | âœ… Offline | 15-30 sek |
| ğŸ“ Generowanie notatek (Qwen) | âœ… Offline | 30-60 sek |
| ğŸ´ Generowanie fiszek (Qwen) | âœ… Offline | 30-60 sek |
| ğŸ“ Generowanie quizÃ³w (Qwen) | âœ… Offline | 30-60 sek |

**ğŸ‰ Wszystko dziaÅ‚a bez internetu po zainstalowaniu modeli!**

---

## ğŸ§ª Test systemu

```bash
npm run test:offline
```

Lub otwÃ³rz: http://localhost:8000/test-offline.html

---

## ğŸ“– PeÅ‚na dokumentacja

- ğŸ“˜ [Przewodnik Offline](./docs/OFFLINE_GUIDE.md) - Kompletny setup i troubleshooting
- ğŸ“„ [ObsÅ‚uga dokumentÃ³w](./docs/DOCUMENT_SUPPORT.md) - PDF i PowerPoint
- ğŸ¬ [PrzykÅ‚ady uÅ¼ycia](./docs/DOCUMENT_EXAMPLES.md) - Scenariusze
- ğŸ”§ [Backend Setup](./docs/BACKEND_SETUP.md) - Konfiguracja
- â“ [FAQ](./docs/FAQ.md) - CzÄ™ste pytania

---

## ğŸ¯ Komfortowy workflow

### 1. Uruchom system (raz na sesjÄ™)
```bash
npm run start:offline
```

### 2. UÅ¼yj aplikacji
- **Nowy wykÅ‚ad** â†’ Nagraj audio lub wgraj PDF/PPT
- **AI generuje** â†’ TytuÅ‚ automatycznie (~30 sek)
- **Zapisz** â†’ WykÅ‚ad gotowy!
- **Generuj materiaÅ‚y** â†’ Notatki, fiszki, quiz (~1 min)

### 3. Ucz siÄ™ offline! ğŸ“

---

## âš™ï¸ Wymagania

### Wymagane:
- **Node.js** 18+ (backend + frontend)
- **Python 3** (frontend server)
- **Ollama** (AI offline)
- **Qwen 2.5:14b** model (~9 GB)

### Opcjonalne:
- Whisper models (tiny: 75MB, base: 142MB, small: 466MB)
- 16+ GB RAM (dla Qwen 14B)
- M1/M2/M3/M4 Mac (najszybsze, ale dziaÅ‚a wszÄ™dzie)

---

## ğŸ’¾ Instalacja modeli

### Qwen (AI - WYMAGANE)
```bash
ollama pull qwen2.5:14b
```

### Whisper (transkrypcja - opcjonalne)
```bash
npm run download-models
```

---

## ğŸ› Problemy?

### "Przycisk nie dziaÅ‚a"
```bash
# OdÅ›wieÅ¼ stronÄ™
Cmd+R lub Ctrl+R

# SprawdÅº konsolÄ™
F12 â†’ Console
```

### "Qwen nie generuje"
```bash
# SprawdÅº czy Ollama dziaÅ‚a
curl http://localhost:11434/api/tags

# JeÅ›li nie, uruchom
ollama serve
```

### "Backend nie odpowiada"
```bash
# SprawdÅº status
curl http://localhost:3001/health

# JeÅ›li nie dziaÅ‚a, uruchom
cd server && npm start
```

---

## ğŸ“Š PorÃ³wnanie modeli AI

| Model | RAM | SzybkoÅ›Ä‡ | JakoÅ›Ä‡ | UÅ¼ycie |
|-------|-----|----------|--------|--------|
| **qwen2.5:14b** | 12GB | 20-30s | â­â­â­â­â­ | Produkcja |
| llama3.1:8b | 8GB | 15-20s | â­â­â­â­ | Alternatywa |
| phi3.5:3.8b | 4GB | 10-15s | â­â­â­ | SzybkoÅ›Ä‡ |

**Rekomendacja: Qwen 2.5:14b** (najlepsza jakoÅ›Ä‡)

---

## ğŸ‰ Enjoy offline learning!

**Happy learning without internet!** ğŸš€

---

## ğŸ”— Linki

- ğŸŒ GitHub: [student_asystent](https://github.com/himusuwu/student_asystent)
- ğŸ“š Docs: [docs/](./docs/)
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/himusuwu/student_asystent/issues)

---

**Wersja:** 2.3.0  
**Data:** 6 paÅºdziernika 2025  
**Licencja:** MIT
