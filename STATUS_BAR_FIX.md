# ğŸ”§ Naprawiono bÅ‚Ä…d 404 Ollama + Dodano Status Bar

## âœ… Naprawione problemy

### 1. **BÅ‚Ä…d 404 z Ollama API**

**Problem:**
```
[Ollama] BÅ‚Ä…d: Ollama API error: 404 Not Found
[Ollama] PrÃ³bujÄ™ fallback na mniejszy model...
[Ollama] WywoÅ‚ujÄ™ model qwen2.5 dla zadania: cleaning  
[Ollama] BÅ‚Ä…d: Ollama API error: 404 Not Found
```

**Przyczyna:**
- Fallback uÅ¼ywaÅ‚ niepeÅ‚nej nazwy modelu (`qwen2.5` zamiast `qwen2.5:14b`)
- Fallback wywoÅ‚ywaÅ‚ `callOllamaAPI` rekurencyjnie, co powodowaÅ‚o nieskoÅ„czonÄ… pÄ™tlÄ™
- Nie sprawdzaÅ‚ dostÄ™pnoÅ›ci modeli przed wywoÅ‚aniem

**RozwiÄ…zanie:**
- âœ… Poprawiono nazwÄ™ fallback modelu na `phi3.5:3.8b`
- âœ… UsuniÄ™to rekurencjÄ™ - fallback wykonuje bezpoÅ›rednie wywoÅ‚anie API
- âœ… Dodano sprawdzanie dostÄ™pnych modeli przez `/api/tags`
- âœ… Dodano lepsze komunikaty bÅ‚Ä™dÃ³w wskazujÄ…ce na `ollama list`

**Kod (ai.ts):**
```typescript
// Fallback na mniejszy model jeÅ›li wiÄ™kszy nie dziaÅ‚a (tylko raz!)
if (model !== 'phi3.5:3.8b') {
  log(`[Ollama] PrÃ³bujÄ™ fallback na phi3.5:3.8b...`)
  const fallbackModel = 'phi3.5:3.8b'
  try {
    const response = await fetch(`${ollamaUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: fallbackModel,
        prompt,
        stream: false,
        options: { temperature: 0.1, top_p: 0.9 }
      })
    })
    // ... obsÅ‚uga odpowiedzi
  } catch (fallbackError) {
    log(`[Ollama] Fallback takÅ¼e nie powiÃ³dÅ‚ siÄ™`)
  }
}
```

### 2. **Dodano Globalny Status Bar**

**FunkcjonalnoÅ›Ä‡:**
- ğŸ¯ Pokazuje aktualnÄ… operacjÄ™ AI
- â±ï¸ Timer pokazujÄ…cy upÅ‚yniÄ™ty czas
- ğŸ“Š Progress bar z animacjÄ…
- â³ Szacowany czas zakoÅ„czenia
- âš ï¸ Oznaczenie gdy operacja trwa dÅ‚uÅ¼ej niÅ¼ szacowany czas

**Pliki:**
- `/src/components/ui/StatusBar.tsx` - gÅ‚Ã³wny komponent
- `/src/pages/App.tsx` - integracja w aplikacji
- `/src/lib/ai.ts` - integracja z operacjami AI

**Status Bar pokazuje:**
```
ğŸ¤– Czyszczenie tekstu AI          Faza: Model: llama3.1:8b
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 85%
â±ï¸ UpÅ‚ynÄ™Å‚o: 2s    â³ PozostaÅ‚o: 0s    Progress: 85%
```

**API do aktualizacji statusu:**
```typescript
import { updateGlobalStatus, clearGlobalStatus, estimateAITime } from '@/components/ui/StatusBar'

// Szacuj czas
const estimatedTime = estimateAITime('cleaning', text.length, 'llama3.1:8b')

// Aktualizuj status
updateGlobalStatus('Czyszczenie tekstu AI', 'Przygotowanie...', 0, estimatedTime)
updateGlobalStatus('Czyszczenie tekstu AI', 'Model: llama3.1:8b', 20, estimatedTime)
updateGlobalStatus('Czyszczenie tekstu AI', 'Analiza zmian...', 90, estimatedTime)
updateGlobalStatus('Czyszczenie tekstu AI', 'Gotowe!', 100, estimatedTime)

// WyczyÅ›Ä‡ po 1.5s
setTimeout(clearGlobalStatus, 1500)
```

**Szacowanie czasu:**
```typescript
estimateAITime(
  'cleaning' | 'notes' | 'flashcards' | 'verification' | 'transcription',
  textLength: number,
  'phi3.5:3.8b' | 'llama3.1:8b' | 'qwen2.5:14b'
): number // zwraca ms
```

**Bazowe czasy (na 1000 znakÃ³w):**
- **Phi-3.5 (3.8B):**
  - Czyszczenie: 1.5s
  - Notatki: 2s
  - Fiszki: 2.5s
  - Weryfikacja: 3s

- **Llama 3.1 (8B):**
  - Czyszczenie: 2s
  - Notatki: 2.5s
  - Fiszki: 3s
  - Weryfikacja: 3.5s

- **Qwen2.5 (14B):**
  - Czyszczenie: 3s
  - Notatki: 4s
  - Fiszki: 5s
  - Weryfikacja: 6s

## ğŸ“¦ Zintegrowane operacje AI

Status bar jest teraz aktywny dla:
- âœ… `cleanTextWithAI()` - czyszczenie tekstu z zacinania
- âœ… `generateNotesWithAI()` - generowanie notatek studenckich
- ğŸ”œ `generateFlashcardsWithAI()` - do zintegrowania
- ğŸ”œ `verifyFactsWithWebSearch()` - do zintegrowania

## ğŸ§ª Testowanie

### Test 1: SprawdÅº dostÄ™pne modele
```bash
ollama list
```

Powinno pokazaÄ‡:
```
NAME           ID              SIZE      MODIFIED       
llama3.1:8b    46e0c10c039e    4.9 GB    X minutes ago    
qwen2.5:14b    7cdf5a0187d5    9.0 GB    X minutes ago    
phi3.5:3.8b    61819fb370a3    2.2 GB    X minutes ago
```

### Test 2: Test API Ollama
```bash
curl -X POST http://localhost:11434/api/generate \
  -d '{"model": "llama3.1:8b", "prompt": "Test: 2+2=", "stream": false}' \
  | jq '.response'
```

Powinno zwrÃ³ciÄ‡: `"The answer is 4."`

### Test 3: Test w aplikacji
1. Uruchom aplikacjÄ™: `npm run dev`
2. PrzejdÅº do "Nowa notatka"
3. Wklej tekst:
```
Dzisiaj, eee, bÄ™dziemy mÃ³-mÃ³-mÃ³wiÄ‡ o p-p-prawdopodobieÅ„stwie 
znalezienia ee-elektronu w w-w-okreÅ›lonym miejscu.
```
4. Kliknij "PrzetwÃ³rz"
5. SprawdÅº czy:
   - âœ… Na dole ekranu pojawia siÄ™ status bar
   - âœ… Pokazuje progress i szacowany czas
   - âœ… Nie ma bÅ‚Ä™dÃ³w 404
   - âœ… Tekst zostaje oczyszczony

### Test 4: Prosty HTML test
OtwÃ³rz plik `test-ai.html` w przeglÄ…darce i przetestuj czyszczenie tekstu.

## ğŸ“Š Status zintegrowanych funkcji

| Funkcja | Status Bar | BÅ‚Ä…d 404 naprawiony | Szacowanie czasu |
|---------|-----------|---------------------|------------------|
| cleanTextWithAI | âœ… | âœ… | âœ… |
| generateNotesWithAI | âœ… | âœ… | âœ… |
| generateFlashcardsWithAI | ğŸ”œ | âœ… | ğŸ”œ |
| verifyFactsWithWebSearch | ğŸ”œ | N/A | ğŸ”œ |

## ğŸš€ NastÄ™pne kroki

1. Zintegruj status bar z `generateFlashcardsWithAI()`
2. Zintegruj status bar z `verifyFactsWithWebSearch()`
3. Dodaj moÅ¼liwoÅ›Ä‡ anulowania operacji AI
4. Dodaj historiÄ™ operacji AI w statusie
5. Zapisuj Å›rednie czasy wykonania dla lepszego szacowania

## ğŸ“ Uwagi

- Status bar jest globalny (singleton) - tylko jedna operacja moÅ¼e byÄ‡ wyÅ›wietlana naraz
- Automatyczne czyszczenie statusu po 1.5s od zakoÅ„czenia operacji
- OstrzeÅ¼enie (âš ï¸) gdy operacja trwa dÅ‚uÅ¼ej niÅ¼ szacowany czas
- Wszystkie operacje logujÄ… do konsoli `[Ollama]` dla debugowania
