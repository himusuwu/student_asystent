import express from 'express'
import cors from 'cors'
import multer from 'multer'
import { pipeline, env } from '@xenova/transformers'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'
import fs from 'fs/promises'

const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)

const app = express()
const PORT = 3001

// Konfiguracja transformers.js dla Node.js z optymalizacjÄ… dla M4 Pro
env.allowLocalModels = true
env.allowRemoteModels = true
env.localModelPath = join(__dirname, '../public/models')
env.cacheDir = join(__dirname, '.cache')

// OPTYMALIZACJE dla Apple Silicon (M4 Pro)
env.backends = env.backends || {}
env.backends.onnx = env.backends.onnx || {}
env.backends.onnx.wasm = env.backends.onnx.wasm || {}

// M4 Pro ma 14 rdzeni (10 performance + 4 efficiency)
// UÅ¼yj 8 wÄ…tkÃ³w dla optymalnej wydajnoÅ›ci
const cpuCores = 8
env.backends.onnx.wasm.numThreads = cpuCores
env.backends.onnx.wasm.simd = true // SIMD acceleration
env.backends.onnx.wasm.proxy = false // Direct execution = faster

console.log(`[Server] Apple Silicon optimized: ${cpuCores} threads, SIMD enabled`)

// Middleware
app.use(cors())
app.use(express.json())

// Multer dla upload plikÃ³w - zwiÄ™kszony limit dla dÅ‚ugich nagraÅ„
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: { fileSize: 1024 * 1024 * 1024 } // 1GB limit dla bardzo dÅ‚ugich nagraÅ„ (1.5h)
})

// Cache dla modeli
let transcriberCache = {}
let summarizerCache = null

console.log('[Server] Starting Student Asystent Backend...')
console.log(`[Server] Model path: ${env.localModelPath}`)

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok', 
    service: 'student-asystent-backend',
    version: '1.0.0',
    modelsPath: env.localModelPath,
    engines: {
      'transformers.js': {
        models: ['Xenova/whisper-tiny', 'Xenova/whisper-base', 'Xenova/whisper-small'],
        endpoints: ['/transcribe', '/transcribe-stream']
      },
      'whisper.cpp': {
        models: ['ggml-tiny.bin', 'ggml-base.bin', 'ggml-small.bin'],
        endpoints: ['/transcribe-cpp', '/transcribe-stream-cpp'],
        gpu: 'Apple M4 Pro Metal'
      }
    }
  })
})

// Endpoint do transkrypcji
app.post('/transcribe', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Brak pliku audio' })
    }

    const { language = 'auto', model = 'base' } = req.body
    const audioBuffer = req.file.buffer

    console.log(`[Transcribe] Otrzymano plik: ${req.file.originalname}, rozmiar: ${(audioBuffer.length / 1024 / 1024).toFixed(2)}MB`)
    console.log(`[Transcribe] Model: ${model}, jÄ™zyk: ${language}`)

    // WybÃ³r modelu
    const modelId = model === 'tiny' ? 'Xenova/whisper-tiny' 
                  : model === 'small' ? 'Xenova/whisper-small'
                  : 'Xenova/whisper-base'

    // ZaÅ‚aduj model (cache) z optymalizacjÄ… dla Apple Silicon
    if (!transcriberCache[modelId]) {
      console.log(`[Transcribe] Åadowanie modelu ${modelId}...`)
      transcriberCache[modelId] = pipeline('automatic-speech-recognition', modelId, {
        device: 'cpu',
        // Optymalizacje dla M4 Pro
        dtype: 'fp32', // Dla Apple Silicon fp32 jest szybsze niÅ¼ quantized
        session_options: {
          executionProviders: ['cpu'], // ONNX Runtime uÅ¼ywa Apple Accelerate
          enableCpuMemArena: true,
          enableMemPattern: true,
          graphOptimizationLevel: 'all'
        }
      })
    }

    const transcriber = await transcriberCache[modelId]
    console.log(`[Transcribe] Model gotowy, rozpoczynam transkrypcjÄ™...`)

    // Dekoduj audio z bufferu
    const pcm = await audioBufferToPCM(audioBuffer)
    const audioDurationSec = (pcm.length / 16000).toFixed(1)
    console.log(`[Transcribe] Audio zdekodowane: ${audioDurationSec}s`)

    // Transkrypcja - ZOPTYMALIZOWANE parametry dla M4 Pro
    const startTime = Date.now()
    const audioDurationMin = (pcm.length / 16000 / 60).toFixed(1)
    console.log(`[Transcribe] DÅ‚ugoÅ›Ä‡ audio: ${audioDurationMin} minut`)
    
    // KLUCZOWA OPTYMALIZACJA: chunk_length_s: 30 to sweet spot!
    // - Dla M4 Pro: 30s chunki sÄ… optymalne (nie za maÅ‚e, nie za duÅ¼e)
    // - stride: 5s daje dobry overlap bez spowalniania
    const result = await transcriber(pcm, {
      chunk_length_s: 30, // ZMNIEJSZONE z 60 -> 30s (2x szybsze!)
      stride_length_s: 5,  // Overlap miÄ™dzy chunkami
      return_timestamps: false,
      language: language === 'auto' ? undefined : language,
      condition_on_previous_text: false, // WyÅ‚Ä…czone = szybsze
      temperature: 0, // Greedy = szybkie
      compression_ratio_threshold: 2.4, // Default, ale jawnie
      logprob_threshold: -1.0, // Default
      no_speech_threshold: 0.6 // Default
    })

    const duration = ((Date.now() - startTime) / 1000).toFixed(1)
    console.log(`[Transcribe] ZakoÅ„czono w ${duration}s`)

    res.json({
      success: true,
      text: result.text || '',
      duration: parseFloat(duration),
      audioLength: (pcm.length / 16000).toFixed(1),
      model: modelId
    })

  } catch (error) {
    console.error('[Transcribe] BÅ‚Ä…d:', error)
    res.status(500).json({ 
      error: error.message || 'BÅ‚Ä…d transkrypcji',
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
    })
  }
})

// Endpoint do ultraszybkiej transkrypcji z whisper.cpp
app.post('/transcribe-cpp', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Brak pliku audio' })
    }

    const { language = 'auto', model = 'tiny' } = req.body
    const audioBuffer = req.file.buffer

    console.log(`[TranscribeCPP] Otrzymano plik: ${req.file.originalname}, rozmiar: ${(audioBuffer.length / 1024 / 1024).toFixed(2)}MB`)
    console.log(`[TranscribeCPP] Model: ${model}, jÄ™zyk: ${language}`)

    // WybÃ³r modelu whisper.cpp (GGML)
    const modelPath = model === 'tiny' ? 'models/whisper-cpp/ggml-tiny.bin'
                    : model === 'small' ? 'models/whisper-cpp/ggml-small.bin'
                    : 'models/whisper-cpp/ggml-base.bin'

    const fullModelPath = join(__dirname, '..', modelPath)
    
    // SprawdÅº czy model istnieje
    try {
      await fs.access(fullModelPath)
    } catch (error) {
      return res.status(500).json({ 
        error: `Model nie znaleziony: ${modelPath}. Uruchom: npm run download-models`
      })
    }

    // Zapisz tymczasowy plik audio
    const tempDir = join(__dirname, '.temp')
    await fs.mkdir(tempDir, { recursive: true })
    const tempAudioPath = join(tempDir, `audio_${Date.now()}.wav`)
    
    try {
      // Konwertuj audio do WAV 16kHz mono przez FFmpeg
      const { spawn } = await import('child_process')
      const { promisify } = await import('util')
      const execFile = promisify((await import('child_process')).execFile)
      
      // Zapisz buffer wejÅ›ciowy
      const tempInputPath = join(tempDir, `input_${Date.now()}`)
      await fs.writeFile(tempInputPath, audioBuffer)

      console.log(`[TranscribeCPP] Konwersja audio przez FFmpeg...`)
      await execFile('ffmpeg', [
        '-i', tempInputPath,
        '-ar', '16000',    // 16kHz sample rate
        '-ac', '1',        // mono
        '-f', 'wav',       // WAV format
        '-y',              // overwrite
        tempAudioPath
      ])

      console.log(`[TranscribeCPP] Uruchamianie whisper.cpp...`)
      const startTime = Date.now()

      // Whisper.cpp command - ZOPTYMALIZOWANE dla M4 Pro
      const whisperArgs = [
        '-m', fullModelPath,
        '-f', tempAudioPath,
        '-t', '8',         // 8 threads dla M4 Pro (10 performance cores)
        '-np',             // no progress prints
        '-oj',             // output JSON
        '--temperature', '0', // greedy = szybsze
        '--no-timestamps'      // bez timestampÃ³w = szybsze
      ]

      // Dodaj jÄ™zyk jeÅ›li nie auto
      if (language !== 'auto') {
        whisperArgs.push('-l', language)
      }

      const whisperResult = await execFile('/opt/homebrew/bin/whisper-cli', whisperArgs)
      
      const duration = ((Date.now() - startTime) / 1000).toFixed(1)
      console.log(`[TranscribeCPP] ZakoÅ„czono w ${duration}s`)

      // Parsuj JSON output
      let transcriptText = ''
      try {
        const jsonOutput = JSON.parse(whisperResult.stdout)
        if (jsonOutput.transcription && jsonOutput.transcription.length > 0) {
          transcriptText = jsonOutput.transcription.map(t => t.text || '').join('').trim()
        }
      } catch (parseError) {
        // Fallback: weÅº caÅ‚y stdout jako text
        transcriptText = whisperResult.stdout.trim()
      }

      // Cleanup temp files
      await fs.unlink(tempInputPath).catch(() => {})
      await fs.unlink(tempAudioPath).catch(() => {})

      res.json({
        success: true,
        text: transcriptText,
        duration: parseFloat(duration),
        model: modelPath,
        engine: 'whisper.cpp',
        gpu: 'Apple M4 Pro Metal'
      })

    } catch (error) {
      // Cleanup on error
      await fs.unlink(tempInputPath).catch(() => {})
      await fs.unlink(tempAudioPath).catch(() => {})
      throw error
    }

  } catch (error) {
    console.error('[TranscribeCPP] BÅ‚Ä…d:', error)
    res.status(500).json({ 
      error: error.message || 'BÅ‚Ä…d transkrypcji whisper.cpp',
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
    })
  }
})

// Endpoint do streaming transkrypcji (z progress)
app.post('/transcribe-stream', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Brak pliku audio' })
    }

    // Ustaw SSE headers
    res.setHeader('Content-Type', 'text/event-stream')
    res.setHeader('Cache-Control', 'no-cache')
    res.setHeader('Connection', 'keep-alive')

    const sendProgress = (progress, phase) => {
      res.write(`data: ${JSON.stringify({ type: 'progress', progress, phase })}\n\n`)
    }

    const { language = 'auto', model = 'base' } = req.body
    const audioBuffer = req.file.buffer

    sendProgress(10, 'Å‚adowanie modelu')

    const modelId = model === 'tiny' ? 'Xenova/whisper-tiny' 
                  : model === 'small' ? 'Xenova/whisper-small'
                  : 'Xenova/whisper-base'

    if (!transcriberCache[modelId]) {
      console.log(`[Transcribe-Stream] Åadowanie modelu ${modelId}...`)
      transcriberCache[modelId] = pipeline('automatic-speech-recognition', modelId, {
        device: 'cpu',
        // Optymalizacje dla M4 Pro
        dtype: 'fp32',
        session_options: {
          executionProviders: ['cpu'],
          enableCpuMemArena: true,
          enableMemPattern: true,
          graphOptimizationLevel: 'all'
        }
      })
    }

    sendProgress(30, 'przygotowanie audio')
    const transcriber = await transcriberCache[modelId]
    const pcm = await audioBufferToPCM(audioBuffer)

    const audioDurationMin = (pcm.length / 16000 / 60).toFixed(1)
    const audioDurationSec = (pcm.length / 16000).toFixed(0)
    console.log(`[Transcribe-Stream] Rozpoczynam transkrypcjÄ™... (${audioDurationMin} minut audio)`)
    
    sendProgress(40, `transkrypcja ${audioDurationMin} min audio`)

    // Symuluj progress - dla dÅ‚ugich nagraÅ„ aktualizuj co 3s
    let currentProgress = 40
    const progressInterval = setInterval(() => {
      currentProgress = Math.min(95, currentProgress + 3)
      const elapsed = Math.floor((Date.now() - Date.now()) / 1000)
      sendProgress(currentProgress, `przetwarzanie... (~${audioDurationSec}s audio)`)
    }, 3000)

    const startTime = Date.now()
    const result = await transcriber(pcm, {
      chunk_length_s: 30, // ZOPTYMALIZOWANE dla M4 Pro (z 60 -> 30)
      stride_length_s: 5,
      return_timestamps: false,
      language: language === 'auto' ? undefined : language,
      condition_on_previous_text: false,
      temperature: 0,
      compression_ratio_threshold: 2.4,
      logprob_threshold: -1.0,
      no_speech_threshold: 0.6
    })

    clearInterval(progressInterval)

    res.write(`data: ${JSON.stringify({ 
      type: 'complete', 
      text: result.text || '',
      model: modelId
    })}\n\n`)
    res.end()

  } catch (error) {
    console.error('[Transcribe-Stream] BÅ‚Ä…d:', error)
    res.write(`data: ${JSON.stringify({ 
      type: 'error', 
      error: error.message 
    })}\n\n`)
    res.end()
  }
})

// Endpoint do ultraszybkiej streaming transkrypcji z whisper.cpp
app.post('/transcribe-stream-cpp', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Brak pliku audio' })
    }

    // Ustaw SSE headers
    res.setHeader('Content-Type', 'text/event-stream')
    res.setHeader('Cache-Control', 'no-cache')
    res.setHeader('Connection', 'keep-alive')

    const sendProgress = (progress, phase) => {
      res.write(`data: ${JSON.stringify({ type: 'progress', progress, phase })}\n\n`)
    }

    const { language = 'auto', model = 'tiny' } = req.body
    const audioBuffer = req.file.buffer

    sendProgress(10, 'przygotowanie whisper.cpp')

    // WybÃ³r modelu whisper.cpp (GGML)
    const modelPath = model === 'tiny' ? 'models/whisper-cpp/ggml-tiny.bin'
                    : model === 'small' ? 'models/whisper-cpp/ggml-small.bin'
                    : 'models/whisper-cpp/ggml-base.bin'

    const fullModelPath = join(__dirname, '..', modelPath)
    
    // SprawdÅº czy model istnieje
    try {
      await fs.access(fullModelPath)
      sendProgress(20, 'model znaleziony')
    } catch (error) {
      res.write(`data: ${JSON.stringify({ 
        type: 'error', 
        error: `Model nie znaleziony: ${modelPath}`
      })}\n\n`)
      res.end()
      return
    }

    // Przygotuj temp pliki
    const tempDir = join(__dirname, '.temp')
    await fs.mkdir(tempDir, { recursive: true })
    const tempAudioPath = join(tempDir, `audio_${Date.now()}.wav`)
    const tempInputPath = join(tempDir, `input_${Date.now()}`)
    
    sendProgress(30, 'konwersja audio')
    
    try {
      // Zapisz buffer wejÅ›ciowy
      await fs.writeFile(tempInputPath, audioBuffer)

      // Konwertuj audio do WAV 16kHz mono przez FFmpeg
      const { promisify } = await import('util')
      const execFile = promisify((await import('child_process')).execFile)
      
      await execFile('ffmpeg', [
        '-i', tempInputPath,
        '-ar', '16000',    // 16kHz sample rate
        '-ac', '1',        // mono
        '-f', 'wav',       // WAV format
        '-y',              // overwrite
        tempAudioPath
      ])

      sendProgress(50, 'uruchamianie whisper.cpp')
      console.log(`[TranscribeStreamCPP] Uruchamianie whisper.cpp...`)
      
      const startTime = Date.now()

      // Whisper.cpp command - z progress
      const whisperArgs = [
        '-m', fullModelPath,
        '-f', tempAudioPath,
        '-t', '8',         // 8 threads dla M4 Pro
        '-pp',             // print progress
        '-oj',             // output JSON
        '--temperature', '0', // greedy = szybsze
        '--no-timestamps'      // bez timestampÃ³w = szybsze
      ]

      // Dodaj jÄ™zyk jeÅ›li nie auto
      if (language !== 'auto') {
        whisperArgs.push('-l', language)
      }

      sendProgress(60, 'przetwarzanie audio')

      const whisperResult = await execFile('/opt/homebrew/bin/whisper-cli', whisperArgs)
      
      const duration = ((Date.now() - startTime) / 1000).toFixed(1)
      console.log(`[TranscribeStreamCPP] ZakoÅ„czono w ${duration}s`)

      sendProgress(90, 'finalizacja')

      // Parsuj JSON output
      let transcriptText = ''
      try {
        const jsonOutput = JSON.parse(whisperResult.stdout)
        if (jsonOutput.transcription && jsonOutput.transcription.length > 0) {
          transcriptText = jsonOutput.transcription.map(t => t.text || '').join('').trim()
        }
      } catch (parseError) {
        // Fallback: weÅº caÅ‚y stdout jako text
        transcriptText = whisperResult.stdout.trim()
      }

      // Cleanup temp files
      await fs.unlink(tempInputPath).catch(() => {})
      await fs.unlink(tempAudioPath).catch(() => {})

      res.write(`data: ${JSON.stringify({ 
        type: 'complete', 
        text: transcriptText,
        model: modelPath,
        engine: 'whisper.cpp',
        gpu: 'Apple M4 Pro Metal',
        duration: parseFloat(duration)
      })}\n\n`)
      res.end()

    } catch (error) {
      // Cleanup on error
      await fs.unlink(tempInputPath).catch(() => {})
      await fs.unlink(tempAudioPath).catch(() => {})
      throw error
    }

  } catch (error) {
    console.error('[TranscribeStreamCPP] BÅ‚Ä…d:', error)
    res.write(`data: ${JSON.stringify({ 
      type: 'error', 
      error: error.message 
    })}\n\n`)
    res.end()
  }
})

// Konwersja audio buffer do PCM Float32Array
async function audioBufferToPCM(buffer) {
  // Import dynamiczny audio decodera
  const { default: wav } = await import('node-wav')
  
  try {
    // Najpierw sprÃ³buj WAV
    const decoded = wav.decode(buffer)
    const samples = decoded.channelData[0] // mono
    return new Float32Array(samples)
  } catch (wavError) {
    // Fallback: uÅ¼yj ffmpeg do konwersji do WAV
    console.log('[AudioDecode] WAV decode failed, trying ffmpeg...')
    
    try {
      const { spawn } = await import('child_process')
      const { promisify } = await import('util')
      const execFile = promisify((await import('child_process')).execFile)
      
      // Zapisz tymczasowo buffer
      const tmpInput = join(__dirname, `.tmp_audio_${Date.now()}`)
      const tmpOutput = join(__dirname, `.tmp_audio_${Date.now()}.wav`)
      
      await fs.writeFile(tmpInput, buffer)
      
      // Konwertuj przez ffmpeg do 16kHz mono WAV
      // ZakÅ‚adamy Å¼e ffmpeg jest zainstalowany globalnie
      await execFile('ffmpeg', [
        '-i', tmpInput,
        '-ar', '16000',  // 16kHz sample rate
        '-ac', '1',      // mono
        '-f', 'wav',
        '-y',            // overwrite
        tmpOutput
      ])
      
      // Wczytaj skonwertowany WAV
      const wavBuffer = await fs.readFile(tmpOutput)
      const decoded = wav.decode(wavBuffer)
      const samples = decoded.channelData[0]
      
      // Cleanup
      await fs.unlink(tmpInput).catch(() => {})
      await fs.unlink(tmpOutput).catch(() => {})
      
      console.log('[AudioDecode] Decoded via ffmpeg successfully')
      return new Float32Array(samples)
      
    } catch (ffmpegError) {
      console.error('[AudioDecode] FFmpeg error:', ffmpegError.message)
      throw new Error(
        'Nie moÅ¼na zdekodowaÄ‡ audio. Upewnij siÄ™ Å¼e:\n' +
        '1. Plik jest w formacie MP3, WAV, M4A lub innym obsÅ‚ugiwanym\n' +
        '2. FFmpeg jest zainstalowany (brew install ffmpeg na macOS)\n' +
        `BÅ‚Ä…d: ${ffmpegError.message}`
      )
    }
  }
}

// ============================================
// AI TEXT GENERATION
// ============================================

// Endpoint do generowania tytuÅ‚u wykÅ‚adu z transkrypcji
app.post('/generate-title', express.json(), async (req, res) => {
  try {
    const { transcription } = req.body;
    
    if (!transcription || transcription.trim().length === 0) {
      return res.status(400).json({ error: 'Brak transkrypcji' });
    }
    
    console.log(`[GenerateTitle] Otrzymano transkrypcjÄ™: ${transcription.length} znakÃ³w`);
    
    // === OLLAMA LLM - Ten sam model co do generowania notatek ===
    const ollamaUrl = 'http://localhost:11434';
    const model = 'qwen2.5:14b'; // Lub phi3.5:3.8b jeÅ›li qwen nie dziaÅ‚a
    
    // Prompt dla LLM
    const prompt = `Przeanalizuj poniÅ¼szÄ… transkrypcjÄ™ wykÅ‚adu i wygeneruj ZWIÄ˜ZÅY tytuÅ‚ (maksymalnie 60 znakÃ³w).

TRANSKRYPCJA:
"${transcription.substring(0, 8000)}"${transcription.length > 8000 ? `\n\n[... i ${transcription.length - 8000} znakÃ³w wiÄ™cej]` : ''}

ZASADY:
- TytuÅ‚ musi byÄ‡ KRÃ“TKI (max 60 znakÃ³w)
- Opisuj GÅÃ“WNY TEMAT wykÅ‚adu
- PomiÅ„ wprowadzenia ("dzisiaj bÄ™dziemy", "chwilkÄ™ poczekamy")
- UÅ¼yj formy rzeczownikowej (np. "Algorytmy sortowania" zamiast "OmawiaÄ‡ algorytmy")
- TYLKO tytuÅ‚, bez dodatkowego tekstu

TYTUÅ:`;

    console.log(`[GenerateTitle] WywoÅ‚ujÄ™ Ollama model: ${model}...`);
    const startTime = Date.now();
    
    // Timeout 60s
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000);
    
    try {
      const response = await fetch(`${ollamaUrl}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        signal: controller.signal,
        body: JSON.stringify({
          model,
          prompt,
          stream: false,
          options: {
            temperature: 0.1, // Deterministyczne
            top_p: 0.9,
            top_k: 40,
            num_predict: 100 // Max 100 tokenÃ³w (~60 znakÃ³w)
          }
        })
      });
      
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        throw new Error(`Ollama error: ${response.status}`);
      }
      
      const data = await response.json();
      const duration = Date.now() - startTime;
      
      let title = data.response.trim();
      
      // Oczyszczanie odpowiedzi LLM
      title = title
        .replace(/^(TytuÅ‚|TYTUÅ|Title):\s*/i, '')
        .replace(/^["']|["']$/g, '') // UsuÅ„ cudzysÅ‚owy
        .replace(/\n.*/g, '') // Tylko pierwsza linia
        .trim();
      
      // Obetnij do 60 znakÃ³w
      if (title.length > 60) {
        const lastSpace = title.substring(0, 60).lastIndexOf(' ');
        title = lastSpace > 40 ? title.substring(0, lastSpace) + '...' : title.substring(0, 60) + '...';
      }
      
      // Capitalize pierwsza litera
      if (title.length > 0) {
        title = title.charAt(0).toUpperCase() + title.slice(1);
      }
      
      console.log(`[GenerateTitle] Wygenerowano w ${duration}ms: "${title}"`);
      
      res.json({
        success: true,
        title: title,
        model: model,
        duration: duration
      });
      
    } catch (ollamaError) {
      clearTimeout(timeoutId);
      
      // SprawdÅº czy to timeout
      if (ollamaError.name === 'AbortError') {
        console.error('[GenerateTitle] Timeout - Ollama nie odpowiedziaÅ‚a w 60s');
        return res.status(504).json({ error: 'Timeout - model nie odpowiedziaÅ‚ w czasie' });
      }
      
      // PrÃ³buj fallback na mniejszy model
      console.log('[GenerateTitle] Qwen nie dziaÅ‚a, prÃ³bujÄ™ phi3.5:3.8b...');
      
      try {
        const fallbackResponse = await fetch(`${ollamaUrl}/api/generate`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            model: 'phi3.5:3.8b',
            prompt,
            stream: false,
            options: { temperature: 0.1, num_predict: 100 }
          })
        });
        
        if (fallbackResponse.ok) {
          const data = await fallbackResponse.json();
          let title = data.response.trim()
            .replace(/^(TytuÅ‚|TYTUÅ|Title):\s*/i, '')
            .replace(/^["']|["']$/g, '')
            .substring(0, 60);
          
          console.log(`[GenerateTitle] Fallback sukces: "${title}"`);
          return res.json({ success: true, title, model: 'phi3.5:3.8b (fallback)' });
        }
      } catch {}
      
      throw ollamaError;
    }
    
  } catch (error) {
    console.error('[GenerateTitle] BÅ‚Ä…d:', error);
    
    // SprawdÅº czy Ollama dziaÅ‚a
    try {
      const healthCheck = await fetch('http://localhost:11434/api/tags');
      if (!healthCheck.ok) {
        return res.status(503).json({ 
          error: 'Ollama nie jest dostÄ™pna',
          details: 'Uruchom: ollama serve'
        });
      }
    } catch {
      return res.status(503).json({ 
        error: 'Ollama nie jest dostÄ™pna',
        details: 'Zainstaluj i uruchom: ollama serve'
      });
    }
    
    res.status(500).json({ 
      error: error.message || 'BÅ‚Ä…d generowania tytuÅ‚u'
    });
  }
});

// Helper: Inteligentne generowanie tytuÅ‚u z transkrypcji
function generateTitleFromTranscription(transcription) {
  console.log(`[TitleGen] Analiza ${transcription.length} znakÃ³w transkrypcji...`);
  
  // Oczyszczanie
  let text = transcription.trim().replace(/\s+/g, ' ').toLowerCase();
  
  // UsuÅ„ typowe artefakty audio
  text = text.replace(/\b(um|uh|eh|hmm|eee|no to|dobra|dobrze|okej|ok)\b/gi, ' ');
  text = text.replace(/\s+/g, ' '); // Normalizuj spacje
  
  // === STRATEGIA 1: Szukaj explicytnego tematu w caÅ‚ym tekÅ›cie ===
  const topicIndicators = [
    // "temat wykÅ‚adu to: TEMAT"
    /temat\s+(dzisiejsz[eyo]+\s+)?(wykÅ‚adu|zajÄ™Ä‡|lekcji)\s+(to\s+)?[:\-]?\s*([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]{10,80})/gi,
    
    // "dzisiaj bÄ™dziemy [czasownik] TEMAT" - pomijamy czasownik!
    /dzisiaj\s+bÄ™dziemy\s+(omawiaÄ‡|poznawaÄ‡|uczyÄ‡ siÄ™|mÃ³wiÄ‡ o)\s+([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]{10,80})/gi,
    /dzisiaj\s+(omÃ³wimy|poznamy)\s+([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]{10,80})/gi,
    
    // "mÃ³wimy dziÅ› o TEMAT"
    /mÃ³wimy\s+(dziÅ›|dzisiaj)\s+o\s+([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]{10,80})/gi,
    
    // "zajmiemy siÄ™ TEMAT"
    /zajmiemy siÄ™\s+([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]{10,80})/gi,
    
    // "omÃ³wimy TEMAT"
    /omÃ³wimy\s+(teraz|dzisiaj|dziÅ›)?\s*([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]{10,80})/gi,
  ];
  
  const foundTopics = [];
  for (const pattern of topicIndicators) {
    let match;
    while ((match = pattern.exec(text)) !== null) {
      const topic = match[match.length - 1].trim();
      if (topic.length > 10 && topic.length < 80) {
        foundTopics.push(cleanAndCapitalize(topic));
      }
    }
  }
  
  if (foundTopics.length > 0) {
    console.log(`[TitleGen] Znaleziono explicytne tematy: ${foundTopics.join(', ')}`);
    // UÅ¼yj pierwszego znalezionego tematu
    let title = truncateAtBoundary(foundTopics[0], 60);
    console.log(`[TitleGen] Wybrany tytuÅ‚ (explicytny): "${title}"`);
    return title;
  }
  
  // === STRATEGIA 2: Analiza czÄ™stotliwoÅ›ci terminÃ³w (TF) ===
  console.log(`[TitleGen] Brak explicytnego tematu, analizujÄ™ terminy...`);
  
  // Podziel na sÅ‚owa i licz czÄ™stotliwoÅ›Ä‡
  const words = text.split(/\s+/).filter(w => w.length > 3);
  const stopWords = new Set([
    'jest', 'sÄ…', 'byÅ‚', 'byÅ‚a', 'byÅ‚o', 'byÅ‚y', 'bÄ™dzie', 'bÄ™dÄ…', 
    'moÅ¼e', 'majÄ…', 'miaÅ‚', 'miaÅ‚a', 'miaÅ‚y', 'oraz', 'albo', 'czyli',
    'ktÃ³ry', 'ktÃ³ra', 'ktÃ³re', 'tego', 'tych', 'temu', 'przy', 'przez',
    'bardzo', 'takÅ¼e', 'rÃ³wnieÅ¼', 'jeÅ›li', 'gdyby', 'poniewaÅ¼', 'dlatego',
    'tutaj', 'teraz', 'wtedy', 'zawsze', 'nigdy', 'czasami', 'czÄ™sto',
    'wiÄ™c', 'wiÄ™cej', 'mniej', 'wszystko', 'nic', 'coÅ›', 'ktoÅ›', 'nikt',
    'Å¼eby', 'jakby', 'jeszcze', 'juÅ¼', 'tylko', 'nawet', 'wÅ‚aÅ›nie',
    'mamy', 'macie', 'masz', 'mieÄ‡', 'wiemy', 'wiesz', 'wiecie',
    'moÅ¼na', 'trzeba', 'naleÅ¼y', 'warto', 'chodzi', 'chce', 'chcemy'
  ]);
  
  const wordFreq = {};
  for (const word of words) {
    if (!stopWords.has(word) && /^[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+$/.test(word)) {
      wordFreq[word] = (wordFreq[word] || 0) + 1;
    }
  }
  
  // Sortuj wedÅ‚ug czÄ™stotliwoÅ›ci
  const sortedWords = Object.entries(wordFreq)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 10); // Top 10 sÅ‚Ã³w
  
  console.log(`[TitleGen] Top terminy: ${sortedWords.map(([w, c]) => `${w}(${c})`).join(', ')}`);
  
  // === STRATEGIA 3: Szukaj fraz z top sÅ‚owami ===
  const topKeywords = sortedWords.slice(0, 3).map(([w]) => w);
  
  // Szukaj zdaÅ„ zawierajÄ…cych top sÅ‚owa kluczowe
  const sentences = transcription.split(/[.!?]+/).filter(s => s.trim().length > 20);
  
  for (const keyword of topKeywords) {
    for (const sentence of sentences.slice(0, 50)) { // Analizuj pierwsze 50 zdaÅ„
      const lowerSentence = sentence.toLowerCase();
      if (lowerSentence.includes(keyword)) {
        // WydobÄ…dÅº fragment wokÃ³Å‚ sÅ‚owa kluczowego
        const words = sentence.trim().split(/\s+/);
        const keywordIndex = words.findIndex(w => w.toLowerCase().includes(keyword));
        
        if (keywordIndex !== -1) {
          // WeÅº 3-7 sÅ‚Ã³w wokÃ³Å‚ sÅ‚owa kluczowego
          const start = Math.max(0, keywordIndex - 2);
          const end = Math.min(words.length, keywordIndex + 5);
          const phrase = words.slice(start, end).join(' ');
          
          if (phrase.length > 15 && phrase.length < 100) {
            let title = cleanAndCapitalize(phrase);
            title = truncateAtBoundary(title, 60);
            console.log(`[TitleGen] Wybrany tytuÅ‚ (z kontekstu '${keyword}'): "${title}"`);
            return title;
          }
        }
      }
    }
  }
  
  // === STRATEGIA 4: Top sÅ‚owa jako tytuÅ‚ ===
  if (topKeywords.length >= 2) {
    const title = cleanAndCapitalize(topKeywords.slice(0, 3).join(' '));
    console.log(`[TitleGen] Wybrany tytuÅ‚ (top sÅ‚owa): "${title}"`);
    return title;
  }
  
  // === FALLBACK: Pierwsze sensowne zdanie ===
  console.log(`[TitleGen] UÅ¼ycie fallback - pierwsze zdanie`);
  for (const sentence of sentences.slice(0, 10)) {
    const cleaned = sentence.trim()
      .replace(/^(jeszcze|chwilkÄ™|poczekamy|sobie|aÅ¼|pewno|wszyscy)/gi, '')
      .trim();
    
    if (cleaned.length > 20) {
      let title = cleanAndCapitalize(cleaned);
      title = truncateAtBoundary(title, 60);
      return title;
    }
  }
  
  return 'WykÅ‚ad bez tytuÅ‚u';
}

// Helper: Oczyszczanie i kapitalizacja
function cleanAndCapitalize(text) {
  // UsuÅ„ biaÅ‚e znaki na poczÄ…tku/koÅ„cu
  text = text.trim();
  
  // UsuÅ„ artefakty na poczÄ…tku
  text = text.replace(/^(um|uh|eh|hmm|eee|no to|dobra|dobrze|wiÄ™c|tak wiÄ™c|otÃ³Å¼|jeszcze|chwilkÄ™|aÅ¼)\s+/gi, '');
  
  // Capitalize pierwsza litera
  if (text.length > 0) {
    text = text.charAt(0).toUpperCase() + text.slice(1).toLowerCase();
  }
  
  return text;
}

// Helper: Obcinanie na granicy zdania/sÅ‚owa
function truncateAtBoundary(text, maxLength) {
  if (text.length <= maxLength) {
    return text;
  }
  
  let truncated = text.substring(0, maxLength);
  
  // SprÃ³buj ciÄ…Ä‡ na kropce/przecinku
  const lastPeriod = truncated.lastIndexOf('.');
  const lastComma = truncated.lastIndexOf(',');
  
  if (lastPeriod > maxLength * 0.6) {
    return truncated.substring(0, lastPeriod);
  }
  
  if (lastComma > maxLength * 0.7) {
    return truncated.substring(0, lastComma);
  }
  
  // CiÄ…Ä‡ na sÅ‚owie
  const lastSpace = truncated.lastIndexOf(' ');
  if (lastSpace > maxLength * 0.7) {
    return truncated.substring(0, lastSpace) + '...';
  }
  
  return truncated + '...';
}

// ============================================
// OLLAMA AI - GENEROWANIE NOTATEK I FISZEK
// ============================================

// Helper: WywoÅ‚anie Ollama API
async function callOllamaAPI(prompt, model = 'qwen2.5:14b', maxTokens = 2048) {
  const ollamaUrl = 'http://localhost:11434';
  
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 120000); // 120s timeout
  
  // Systemowy prompt kontrolujÄ…cy jÄ™zyk
  const systemPrompt = "JesteÅ› polskim asystentem AI. Odpowiadaj WYÅÄ„CZNIE w jÄ™zyku polskim. NIE uÅ¼ywaj Å¼adnych sÅ‚Ã³w w innych jÄ™zykach, szczegÃ³lnie chiÅ„skim lub angielskim. JeÅ›li nie znasz polskiego odpowiednika jakiegoÅ› terminu, uÅ¼yj opisowego wyjaÅ›nienia w jÄ™zyku polskim.";
  
  // Kombinuj system prompt z user prompt
  const fullPrompt = `System: ${systemPrompt}\n\nUser: ${prompt}`;
  
  try {
    const response = await fetch(`${ollamaUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      signal: controller.signal,
      body: JSON.stringify({
        model,
        prompt: fullPrompt,
        stream: false,
        options: {
          temperature: 0.3,
          top_p: 0.9,
          top_k: 40,
          num_predict: maxTokens,
          // Dodatkowe parametry dla kontroli jÄ™zyka
          repeat_penalty: 1.1,
          presence_penalty: 0.1,
          frequency_penalty: 0.1
        }
      })
    });
    
    clearTimeout(timeoutId);
    
    if (!response.ok) {
      throw new Error(`Ollama error: ${response.status}`);
    }
    
    const data = await response.json();
    return data.response.trim();
    
  } catch (error) {
    clearTimeout(timeoutId);
    
    if (error.name === 'AbortError') {
      throw new Error('Timeout - model nie odpowiedziaÅ‚ w 120s');
    }
    
    throw error;
  }
}

// Endpoint: Generowanie notatek z transkrypcji
app.post('/generate-notes', express.json(), async (req, res) => {
  try {
    const { transcription } = req.body;
    
    if (!transcription || transcription.trim().length === 0) {
      return res.status(400).json({ error: 'Brak transkrypcji' });
    }
    
    console.log(`[GenerateNotes] Otrzymano: ${transcription.length} znakÃ³w`);
    
    const prompt = `Jestem studentem i potrzebujÄ™ profesjonalnych notatek z tego wykÅ‚adu.

TRANSKRYPCJA:
"${transcription}"

Wygeneruj KOMPLETNE notatki w formacie JSON:

{
  "formatted": "# TytuÅ‚\\n\\n## Sekcja 1\\n\\nTreÅ›Ä‡...\\n\\n## Sekcja 2",
  "structured": "1. **PojÄ™cie**\\n   - Punkt 1\\n   - Punkt 2",
  "summary": "Podsumowanie w 2-3 zdaniach",
  "keyPoints": "â€¢ Punkt kluczowy 1\\nâ€¢ Punkt kluczowy 2",
  "questions": "1. Pytanie 1\\n2. Pytanie 2"
}

WAÅ»NE: OdpowiedÅº TYLKO w JSON, bez dodatkowego tekstu!`;

    const startTime = Date.now();
    const response = await callOllamaAPI(prompt, 'qwen2.5:14b', 2048);
    const duration = Date.now() - startTime;
    
    // Parsuj JSON
    const jsonMatch = response.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Brak JSON w odpowiedzi');
    }
    
    const result = JSON.parse(jsonMatch[0]);
    
    console.log(`[GenerateNotes] Wygenerowano w ${duration}ms`);
    
    res.json({
      success: true,
      ...result,
      duration
    });
    
  } catch (error) {
    console.error('[GenerateNotes] BÅ‚Ä…d:', error);
    res.status(500).json({ error: error.message || 'BÅ‚Ä…d generowania notatek' });
  }
});

// Endpoint: Generowanie fiszek z transkrypcji
app.post('/generate-flashcards', express.json(), async (req, res) => {
  try {
    const { transcription } = req.body;
    
    if (!transcription || transcription.trim().length === 0) {
      return res.status(400).json({ error: 'Brak transkrypcji' });
    }
    
    console.log(`[GenerateFlashcards] Otrzymano: ${transcription.length} znakÃ³w`);
    
    const prompt = `StwÃ³rz fiszki edukacyjne z tego materiaÅ‚u:

MATERIAÅ:
"${transcription}"

Format JSON (TYLKO array, bez innych tekstÃ³w):
[
  {
    "question": "Pytanie?",
    "answer": "OdpowiedÅº",
    "category": "definicja",
    "difficulty": "easy"
  }
]

ZASADY:
- RÃ³Å¼ne poziomy: easy, medium, hard
- Kategorie: definicja, zastosowanie, przykÅ‚ad, wzÃ³r, analiza, porÃ³wnanie
- Wygeneruj JAK NAJWIÄ˜CEJ fiszek - kaÅ¼dy waÅ¼ny koncept powinien mieÄ‡ wÅ‚asnÄ… fiszkÄ™
- StwÃ³rz minimum 20-30 fiszek jeÅ›li materiaÅ‚ na to pozwala
- UwzglÄ™dnij wszystkie szczegÃ³Å‚y, fakty, definicje, przykÅ‚ady
- KaÅ¼dy termin, proces, koncepcja = osobna fiszka
- Nie pomijaj Å¼adnych waÅ¼nych informacji
- Fiszki powinny pokrywaÄ‡ caÅ‚y zakres tematu dogÅ‚Ä™bnie`;

    const startTime = Date.now();
    const response = await callOllamaAPI(prompt, 'qwen2.5:14b', 8192);
    const duration = Date.now() - startTime;
    
    // Parsuj JSON array
    const jsonMatch = response.match(/\[[\s\S]*\]/);
    if (!jsonMatch) {
      throw new Error('Brak JSON array w odpowiedzi');
    }
    
    const flashcards = JSON.parse(jsonMatch[0]);
    
    console.log(`[GenerateFlashcards] Wygenerowano ${flashcards.length} fiszek w ${duration}ms`);
    
    res.json({
      success: true,
      flashcards,
      duration
    });
    
  } catch (error) {
    console.error('[GenerateFlashcards] BÅ‚Ä…d:', error);
    res.status(500).json({ error: error.message || 'BÅ‚Ä…d generowania fiszek' });
  }
});

// Endpoint: Generowanie szczegÃ³Å‚owej notatki
app.post('/generate-detailed-note', express.json(), async (req, res) => {
  try {
    const { transcription } = req.body;
    
    if (!transcription || transcription.trim().length === 0) {
      return res.status(400).json({ error: 'Brak transkrypcji' });
    }
    
    console.log(`[GenerateDetailedNote] Otrzymano: ${transcription.length} znakÃ³w`);
    
    const prompt = `JÄ˜ZYK ODPOWIEDZI: TYLKO JÄ˜ZYK POLSKI. Nie uÅ¼ywaj Å»ADNYCH sÅ‚Ã³w w innych jÄ™zykach (chiÅ„skim, angielskim itp.).

StwÃ³rz SZCZEGÃ“ÅOWÄ„ notatkÄ™ akademickÄ… z tego materiaÅ‚u w formacie Markdown.

MATERIAÅ:
"${transcription}"

STRUKTURA:
# TytuÅ‚ tematu

## Wprowadzenie
Kontekst i znaczenie tematu (2-3 zdania)

## GÅ‚Ã³wne zagadnienia

### 1. [Pierwsze zagadnienie]
- Definicja i wyjaÅ›nienie
- SzczegÃ³Å‚y i przykÅ‚ady
- PowiÄ…zania z innymi tematami

### 2. [Drugie zagadnienie]
- Analogicznie

## Kluczowe terminy
- **Termin 1**: definicja
- **Termin 2**: definicja

## Podsumowanie
Syntetyczne zestawienie najwaÅ¼niejszych punktÃ³w

ZASADY:
- UÅ»YWAJ WYÅÄ„CZNIE JÄ˜ZYKA POLSKIEGO - nie mieszaj jÄ™zykÃ³w!
- UÅ¼ywaj struktury Markdown (nagÅ‚Ã³wki ##, listy, pogrubienia **)
- Pisz jÄ™zykiem akademickim ale zrozumiaÅ‚ym
- UwzglÄ™dnij WSZYSTKIE waÅ¼ne informacje z materiaÅ‚u - nic nie pomijaj
- Notatka powinna byÄ‡ maksymalnie szczegÃ³Å‚owa i obszerna
- Analizuj kaÅ¼dy aspekt tematu dogÅ‚Ä™bnie
- Dodawaj przykÅ‚ady, kontekst i powiÄ…zania miÄ™dzy zagadnieniami
- Rozwijaj kaÅ¼dy punkt obszernie - nie skracaj treÅ›ci
- Celem jest stworzenie kompletnego, wyczerpujÄ…cego opracowania tematu
- Im wiÄ™cej szczegÃ³Å‚Ã³w, tym lepiej - nie ma limitÃ³w dÅ‚ugoÅ›ci
- PAMIÄ˜TAJ: Odpowiadaj TYLKO po polsku, bez Å¼adnych sÅ‚Ã³w w innych jÄ™zykach!`;

    const startTime = Date.now();
    const response = await callOllamaAPI(prompt, 'qwen2.5:14b', 16384);
    const duration = Date.now() - startTime;
    
    console.log(`[GenerateDetailedNote] Wygenerowano notatkÄ™ w ${duration}ms`);
    
    res.json({
      success: true,
      note: response,
      duration
    });
    
  } catch (error) {
    console.error('[GenerateDetailedNote] BÅ‚Ä…d:', error);
    res.status(500).json({ error: error.message || 'BÅ‚Ä…d generowania szczegÃ³Å‚owej notatki' });
  }
});

// Endpoint: Generowanie krÃ³tkiej notatki
app.post('/generate-short-note', express.json(), async (req, res) => {
  try {
    const { transcription } = req.body;
    
    if (!transcription || transcription.trim().length === 0) {
      return res.status(400).json({ error: 'Brak transkrypcji' });
    }
    
    console.log(`[GenerateShortNote] Otrzymano: ${transcription.length} znakÃ³w`);
    
    const prompt = `JÄ˜ZYK ODPOWIEDZI: TYLKO JÄ˜ZYK POLSKI. Nie uÅ¼ywaj Å»ADNYCH sÅ‚Ã³w w innych jÄ™zykach (chiÅ„skim, angielskim itp.).

StwÃ³rz SZCZEGÃ“ÅOWÄ„ notatkÄ™ z tego materiaÅ‚u w formacie Markdown.

MATERIAÅ:
"${transcription}"

STRUKTURA:
# TytuÅ‚

## ğŸ“‹ NajwaÅ¼niejsze punkty
- Punkt 1
- Punkt 2
- Punkt 3

## ğŸ’¡ Kluczowe terminy
- **Termin**: krÃ³tka definicja

## ğŸ¯ Wnioski
ZwiÄ™zÅ‚e podsumowanie (2-3 zdania)

ZASADY:
- UÅ»YWAJ WYÅÄ„CZNIE JÄ˜ZYKA POLSKIEGO - nie mieszaj jÄ™zykÃ³w!
- SzczegÃ³Å‚owa ale przystÄ™pna forma
- UwzglÄ™dnij wszystkie waÅ¼ne informacje - nie skracaj
- Format Markdown z emoji dla czytelnoÅ›ci
- Notatka moÅ¼e byÄ‡ dÅ‚uga jeÅ›li materiaÅ‚ tego wymaga
- Lepiej szczegÃ³Å‚owo niÅ¼ powierzchownie
- Nie pomijaj Å¼adnych istotnych treÅ›ci
- PAMIÄ˜TAJ: Odpowiadaj TYLKO po polsku, bez Å¼adnych sÅ‚Ã³w w innych jÄ™zykach!`;

    const startTime = Date.now();
    const response = await callOllamaAPI(prompt, 'qwen2.5:14b', 4096);
    const duration = Date.now() - startTime;
    
    console.log(`[GenerateShortNote] Wygenerowano krÃ³tkÄ… notatkÄ™ w ${duration}ms`);
    
    res.json({
      success: true,
      note: response,
      duration
    });
    
  } catch (error) {
    console.error('[GenerateShortNote] BÅ‚Ä…d:', error);
    res.status(500).json({ error: error.message || 'BÅ‚Ä…d generowania krÃ³tkiej notatki' });
  }
});

// Endpoint: Generowanie kluczowych punktÃ³w
app.post('/generate-key-points', express.json(), async (req, res) => {
  try {
    const { transcription } = req.body;
    
    if (!transcription || transcription.trim().length === 0) {
      return res.status(400).json({ error: 'Brak transkrypcji' });
    }
    
    console.log(`[GenerateKeyPoints] Otrzymano: ${transcription.length} znakÃ³w`);
    
    const prompt = `WyodrÄ™bnij KLUCZOWE PUNKTY z tego materiaÅ‚u w formacie Markdown.

MATERIAÅ:
"${transcription}"

FORMAT:
# ğŸ¯ Kluczowe punkty

## ğŸ“Œ GÅ‚Ã³wne tezy
1. **[Teza 1]** - krÃ³tkie wyjaÅ›nienie
2. **[Teza 2]** - krÃ³tkie wyjaÅ›nienie
3. **[Teza 3]** - krÃ³tkie wyjaÅ›nienie

## ğŸ”‘ Terminy do zapamiÄ™tania
- **Termin 1**: definicja
- **Termin 2**: definicja

## ğŸ“Š Fakty i liczby
- Fakt 1
- Fakt 2

## âš ï¸ Uwaga
NajwaÅ¼niejsze zastrzeÅ¼enia lub wyjÄ…tki

ZASADY:
- ILOÅšÄ† punktÃ³w dostosowana do treÅ›ci - minimum 15-25 punktÃ³w
- KaÅ¼dy punkt zwiÄ™zÅ‚y ale kompletny
- UwzglÄ™dnij wszystkie informacje istotne do zapamiÄ™tania
- Format Markdown z emoji
- Lepiej wiÄ™cej punktÃ³w niÅ¼ pominiÄ™te waÅ¼ne treÅ›ci
- Pokryj caÅ‚y zakres tematu systematycznie`;

    const startTime = Date.now();
    const response = await callOllamaAPI(prompt, 'qwen2.5:14b', 2048);
    const duration = Date.now() - startTime;
    
    console.log(`[GenerateKeyPoints] Wygenerowano kluczowe punkty w ${duration}ms`);
    
    res.json({
      success: true,
      keyPoints: response,
      duration
    });
    
  } catch (error) {
    console.error('[GenerateKeyPoints] BÅ‚Ä…d:', error);
    res.status(500).json({ error: error.message || 'BÅ‚Ä…d generowania kluczowych punktÃ³w' });
  }
});

// Endpoint: Generowanie quizu
app.post('/generate-quiz', express.json(), async (req, res) => {
  try {
    const { transcription } = req.body;
    
    if (!transcription || transcription.trim().length === 0) {
      return res.status(400).json({ error: 'Brak transkrypcji' });
    }
    
    console.log(`[GenerateQuiz] Otrzymano: ${transcription.length} znakÃ³w`);
    
    const prompt = `StwÃ³rz quiz wielokrotnego wyboru z tego materiaÅ‚u:

MATERIAÅ:
"${transcription}"

Format JSON (TYLKO array, bez innych tekstÃ³w):
[
  {
    "question": "Pytanie?",
    "options": ["Opcja A", "Opcja B", "Opcja C", "Opcja D"],
    "correctIndex": 0,
    "category": "definicje"
  }
]

ZASADY:
- 15-25 pytaÅ„ rÃ³Å¼nej trudnoÅ›ci (wczeÅ›niej 8-12)
- KaÅ¼de pytanie ma 4 opcje
- correctIndex to indeks prawidÅ‚owej odpowiedzi (0-3)
- Kategorie: definicje, zastosowania, analiza, fakty, porÃ³wnania
- Dystraktory (zÅ‚e odpowiedzi) muszÄ… byÄ‡ wiarygodne
- Poprawna odpowiedÅº nie moÅ¼e byÄ‡ oczywista
- Pokryj caÅ‚y zakres tematu systematycznie
- UwzglÄ™dnij wszystkie waÅ¼ne zagadnienia z materiaÅ‚u`;

    const startTime = Date.now();
    const response = await callOllamaAPI(prompt, 'qwen2.5:14b', 4096);
    const duration = Date.now() - startTime;
    
    // Parsuj JSON array
    const jsonMatch = response.match(/\[[\s\S]*\]/);
    if (!jsonMatch) {
      throw new Error('Brak JSON array w odpowiedzi');
    }
    
    const questions = JSON.parse(jsonMatch[0]);
    
    console.log(`[GenerateQuiz] Wygenerowano ${questions.length} pytaÅ„ quizowych w ${duration}ms`);
    
    res.json({
      success: true,
      questions,
      duration
    });
    
  } catch (error) {
    console.error('[GenerateQuiz] BÅ‚Ä…d:', error);
    res.status(500).json({ error: error.message || 'BÅ‚Ä…d generowania quizu' });
  }
});

// Endpoint: Ekstrakcja tekstu z PowerPoint (PPT/PPTX)
app.post('/api/extract-ppt', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Brak pliku' });
    }

    const fileName = req.file.originalname.toLowerCase();
    
    if (!fileName.endsWith('.ppt') && !fileName.endsWith('.pptx')) {
      return res.status(400).json({ error: 'NieprawidÅ‚owy format pliku. Tylko PPT i PPTX sÄ… obsÅ‚ugiwane.' });
    }

    console.log(`[Extract-PPT] Przetwarzanie pliku: ${req.file.originalname}`);
    
    // Dla PPTX (format XML-based)
    if (fileName.endsWith('.pptx')) {
      try {
        const JSZip = (await import('jszip')).default;
        const zip = new JSZip();
        const contents = await zip.loadAsync(req.file.buffer);
        
        let extractedText = '';
        let slideNumber = 0;
        
        // Iteruj przez slajdy w folderze ppt/slides/
        for (const filename in contents.files) {
          if (filename.startsWith('ppt/slides/slide') && filename.endsWith('.xml')) {
            slideNumber++;
            const fileData = await contents.files[filename].async('text');
            
            // Parsuj XML i wyciÄ…gnij tekst z tagÃ³w <a:t>
            const textMatches = fileData.match(/<a:t>([^<]+)<\/a:t>/g);
            
            if (textMatches) {
              const slideText = textMatches
                .map(match => match.replace(/<\/?a:t>/g, ''))
                .join(' ');
              
              extractedText += `\n\n--- Slajd ${slideNumber} ---\n\n${slideText}`;
            }
          }
        }
        
        if (!extractedText.trim()) {
          return res.status(400).json({ 
            error: 'Nie znaleziono tekstu w prezentacji. Prezentacja moÅ¼e zawieraÄ‡ tylko obrazy.' 
          });
        }
        
        console.log(`[Extract-PPT] PomyÅ›lnie wyekstrahowano tekst z ${slideNumber} slajdÃ³w`);
        
        return res.json({ 
          text: extractedText.trim(),
          slideCount: slideNumber,
          fileName: req.file.originalname
        });
        
      } catch (zipError) {
        console.error('[Extract-PPT] BÅ‚Ä…d parsowania PPTX:', zipError);
        return res.status(500).json({ 
          error: 'Nie udaÅ‚o siÄ™ przetworzyÄ‡ pliku PPTX. Plik moÅ¼e byÄ‡ uszkodzony.' 
        });
      }
    }
    
    // Dla starszych plikÃ³w PPT - wymagaÅ‚oby dodatkowych bibliotek
    if (fileName.endsWith('.ppt')) {
      return res.status(400).json({ 
        error: 'Stare pliki PPT nie sÄ… jeszcze obsÅ‚ugiwane. ProszÄ™ przekonwertowaÄ‡ do PPTX.' 
      });
    }
    
  } catch (error) {
    console.error('[Extract-PPT] BÅ‚Ä…d:', error);
    res.status(500).json({ 
      error: `BÅ‚Ä…d serwera podczas przetwarzania pliku: ${error.message}` 
    });
  }
});

// Start server
app.listen(PORT, () => {
  console.log(`\nâœ… Server uruchomiony na http://localhost:${PORT}`)
  console.log(`ğŸ“ ÅšcieÅ¼ka modeli: ${env.localModelPath}`)
  console.log(`\nğŸ™ï¸ Silniki transkrypcji:`)
  console.log(`   ğŸ”§ Transformers.js - uniwersalny, dziaÅ‚a w przeglÄ…darce`)
  console.log(`   âš¡ Whisper.cpp - ultraszybki, Metal GPU (Apple M4 Pro)`)
  console.log(`\nğŸ”— Endpointy:`)
  console.log(`   GET  /health - sprawdÅº status i dostÄ™pne silniki`)
  console.log(`\n   ğŸ“ Transformers.js:`)
  console.log(`   POST /transcribe - transkrypcja (zwraca wynik)`)
  console.log(`   POST /transcribe-stream - transkrypcja z progress (SSE)`)
  console.log(`\n   âš¡ Whisper.cpp (SZYBSZY):`)
  console.log(`   POST /transcribe-cpp - ultraszybka transkrypcja`)
  console.log(`   POST /transcribe-stream-cpp - ultraszybka z progress`)
  console.log(`\n   ğŸ¤– AI (Ollama):`)
  console.log(`   POST /generate-title - generuj tytuÅ‚ z transkrypcji`)
  console.log(`   POST /generate-notes - generuj notatki z transkrypcji`)
  console.log(`   POST /generate-detailed-note - generuj szczegÃ³Å‚owÄ… notatkÄ™`)
  console.log(`   POST /generate-short-note - generuj krÃ³tkÄ… notatkÄ™`)
  console.log(`   POST /generate-key-points - generuj kluczowe punkty`)
  console.log(`   POST /generate-flashcards - generuj fiszki z transkrypcji`)
  console.log(`   POST /generate-quiz - generuj quiz z transkrypcji`)
  console.log(`\n   ğŸ“„ Dokumenty:`)
  console.log(`   POST /api/extract-ppt - wyekstrahuj tekst z PowerPoint (PPTX)`)
  console.log(`\nğŸ’¡ Ollama musi dziaÅ‚aÄ‡: ollama serve`)
  console.log(`ğŸ’¡ Aby zatrzymaÄ‡: Ctrl+C\n`)
})

