# Student Asystent - Backend Server

Lokalny serwer Node.js do transkrypcji audio za pomocÄ… Whisper AI.

## ğŸš€ Zalety backendu

- âœ… **Nie blokuje przeglÄ…darki** - strona dziaÅ‚a pÅ‚ynnie podczas transkrypcji
- âœ… **Szybsza transkrypcja** - lepsze wykorzystanie zasobÃ³w CPU
- âœ… **PeÅ‚na prywatnoÅ›Ä‡** - wszystko dziaÅ‚a lokalnie na twoim komputerze
- âœ… **MoÅ¼liwoÅ›Ä‡ uÅ¼ycia GPU** (opcjonalnie z CUDA)

## ğŸ“¦ Instalacja

```bash
cd server
npm install
```

## â–¶ï¸ Uruchomienie

```bash
npm start
```

Serwer uruchomi siÄ™ na `http://localhost:3001`

### Tryb deweloperski (auto-restart)

```bash
npm run dev
```

## ğŸ”§ Konfiguracja

Server domyÅ›lnie:
- Port: **3001**
- Modele: czyta z `../public/models` (moÅ¼esz zmieniÄ‡ w `server.js`)
- CORS: wÅ‚Ä…czony dla localhost

## ğŸ“¡ Endpointy

### `GET /health`
Sprawdza status serwera

**Response:**
```json
{
  "status": "ok",
  "service": "student-asystent-backend",
  "version": "1.0.0",
  "modelsPath": "/path/to/models"
}
```

### `POST /transcribe`
Transkrypcja audio (zwraca peÅ‚ny wynik)

**Request:**
- Method: POST
- Content-Type: multipart/form-data
- Fields:
  - `audio`: plik audio (MP3, WAV, etc.)
  - `language`: 'pl' | 'en' | 'auto' (opcjonalnie)
  - `model`: 'tiny' | 'base' | 'small' (opcjonalnie)

**Response:**
```json
{
  "success": true,
  "text": "Transkrypcja tekstu...",
  "duration": 2.5,
  "audioLength": "15.2",
  "model": "Xenova/whisper-base"
}
```

### `POST /transcribe-stream`
Transkrypcja z postÄ™pem (Server-Sent Events)

**Request:** (jak `/transcribe`)

**Response:** SSE stream
```
data: {"type":"progress","progress":10,"phase":"Å‚adowanie modelu"}
data: {"type":"progress","progress":40,"phase":"transkrypcja"}
data: {"type":"complete","text":"Transkrypcja...","model":"Xenova/whisper-base"}
```

## ğŸ” Troubleshooting

### Backend nie uruchamia siÄ™
- SprawdÅº czy port 3001 nie jest zajÄ™ty
- Upewnij siÄ™ Å¼e zainstalowaÅ‚eÅ› dependencies (`npm install`)

### "NieobsÅ‚ugiwany format audio"
- âš ï¸ **WAÅ»NE: Zainstaluj FFmpeg!**
  
  **macOS:**
  ```bash
  brew install ffmpeg
  ```
  
  **Ubuntu/Debian:**
  ```bash
  sudo apt-get install ffmpeg
  ```
  
  **Windows:**
  Pobierz z https://ffmpeg.org/download.html i dodaj do PATH

- SprawdÅº czy ffmpeg dziaÅ‚a: `which ffmpeg` (macOS/Linux) lub `where ffmpeg` (Windows)
- Wspierane formaty z FFmpeg: MP3, M4A, WAV, OGG, FLAC i inne

### Brak modeli
- Modele powinny byÄ‡ w `../public/models/Xenova/whisper-*`
- MoÅ¼esz zmieniÄ‡ Å›cieÅ¼kÄ™ w `server.js` w zmiennej `env.localModelPath`

## ğŸ› ï¸ RozwÃ³j

### Dodanie wsparcia dla GPU (CUDA)

1. Zainstaluj ONNX Runtime z CUDA:
```bash
npm install onnxruntime-node-gpu
```

2. ZmieÅ„ `device: 'cpu'` na `device: 'cuda'` w `server.js`

### Dodanie wsparcia dla wiÄ™cej formatÃ³w audio

Zainstaluj ffmpeg i dodaj decoder:
```bash
npm install fluent-ffmpeg
```

## ğŸ“ Licencja

CzÄ™Å›Ä‡ projektu Student Asystent - patrz gÅ‚Ã³wny README.
