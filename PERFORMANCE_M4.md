# ğŸš€ Optymalizacja wydajnoÅ›ci na Apple Silicon (M4 Pro)

## âœ… Zaimplementowane optymalizacje

### 1. **Chunk Length: 30s (zamiast 60s)**
- **Dlaczego**: 30s to sweet spot dla Whisper na M4 Pro
- **Efekt**: ~2x szybsza transkrypcja dÅ‚ugich nagraÅ„
- **Poprzednio**: 60s chunki powodowaÅ‚y wysokie zuÅ¼ycie RAM i wolniejsze przetwarzanie
- **Teraz**: Optymalna rÃ³wnowaga miÄ™dzy prÄ™dkoÅ›ciÄ… a dokÅ‚adnoÅ›ciÄ…

### 2. **WASM Threading: 8 wÄ…tkÃ³w**
- **Wykorzystanie**: M4 Pro ma 14 rdzeni (10 P-cores + 4 E-cores)
- **Ustawienie**: 8 wÄ…tkÃ³w to optimum (nie za maÅ‚o, nie za duÅ¼o)
- **SIMD**: WÅ‚Ä…czone (Single Instruction Multiple Data acceleration)

### 3. **ONNX Runtime Optimizations**
- `enableCpuMemArena: true` - lepsza alokacja pamiÄ™ci
- `enableMemPattern: true` - optymalizacja dostÄ™pu do pamiÄ™ci
- `graphOptimizationLevel: 'all'` - maksymalna optymalizacja grafu

### 4. **FP32 dtype (zamiast quantized)**
- Apple Silicon ma Å›wietne wsparcie dla FP32
- Quantized modele (int8, fp16) sÄ… WOLNIEJSZE na M4 bez GPU support

## âš¡ Oczekiwane czasy transkrypcji

Z modelem **whisper-base** na M4 Pro:

| DÅ‚ugoÅ›Ä‡ audio | Czas transkrypcji | Ratio |
|---------------|-------------------|-------|
| 1 minuta      | ~5-8 sekund       | ~8-10x |
| 5 minut       | ~25-40 sekund     | ~7-12x |
| 10 minut      | ~50-90 sekund     | ~6-12x |
| 30 minut      | ~3-5 minut        | ~6-10x |
| 60 minut      | ~6-10 minut       | ~6-10x |

> **Cel**: Maksymalnie 1 minuta dla 60 minut audio âŒ (nierealne)
> **Realistyczny cel**: 6-10 minut dla 60 minut audio âœ…

## ğŸ”§ Dalsze optymalizacje (jeÅ›li potrzebujesz JESZCZE szybciej)

### 1. **UÅ¼yj mniejszego modelu**
```javascript
model: 'tiny' // zamiast 'base'
```
- **whisper-tiny**: ~2-3x szybszy niÅ¼ base
- **DokÅ‚adnoÅ›Ä‡**: 85-90% (vs 92-95% dla base)
- **Dla wykÅ‚adÃ³w**: Tiny czÄ™sto wystarczy!

### 2. **Batch Processing (wiele plikÃ³w jednoczeÅ›nie)**
- M4 Pro radzi sobie z 2-3 transkrypcjami rÃ³wnolegle
- Uruchom kilka instancji backendu (rÃ³Å¼ne porty)

### 3. **Whisper.cpp (natywna implementacja)**
Zamiast transformers.js, uÅ¼yj whisper.cpp:
```bash
brew install whisper-cpp
```
- **PrÄ™dkoÅ›Ä‡**: 3-5x szybszy niÅ¼ transformers.js
- **Wsparcie**: Metal (GPU na Apple Silicon)
- **Wada**: Wymaga instalacji zewnÄ™trznego narzÄ™dzia

### 4. **Cloud API (dla bardzo dÅ‚ugich nagraÅ„)**
Dla nagraÅ„ >60 minut rozwaÅ¼:
- OpenAI Whisper API ($0.006/min)
- Assembly.AI
- Deepgram

## ğŸ“Š Monitoring wydajnoÅ›ci

SprawdÅº w logach backendu:
```
[Transcribe] Audio zdekodowane: 125.4s
[Transcribe] ZakoÅ„czono w 18.2s
```

**WskaÅºnik wydajnoÅ›ci**: 
- Ratio = Czas audio / Czas transkrypcji
- **Dobry**: >6x (125s audio w 18s = 6.9x) âœ…
- **SÅ‚aby**: <4x (potrzeba optymalizacji)

## ğŸ¯ Realistyczne oczekiwania

**NIE jest moÅ¼liwe**:
- âŒ 60 minut audio w 1 minutÄ™ (60x realtime)
- âŒ Transkrypcja szybsza niÅ¼ odsÅ‚uchanie

**JEST moÅ¼liwe**:
- âœ… 60 minut audio w 6-10 minut (6-10x realtime)
- âœ… 10 minut audio w ~1 minutÄ™ (10x realtime)

### Dlaczego NIE moÅ¼na szybciej?

1. **Model musi przetworzyÄ‡ kaÅ¼dy chunk**
   - Whisper to transformer = kosztowne obliczenia
   - Nawet na najlepszych procesorach

2. **Dekodowanie audio zajmuje czas**
   - Konwersja MP3/M4A -> PCM 16kHz mono
   - FFmpeg dekodowanie

3. **Ograniczenia WASM/CPU**
   - Brak natywnego Metal/GPU support w transformers.js
   - ONNX Runtime WASM jest szybkie, ale nie jak natywny kod

## ğŸ’¡ Rekomendacja

Dla **najlepszej rÃ³wnowagi prÄ™dkoÅ›Ä‡/dokÅ‚adnoÅ›Ä‡**:

1. **KrÃ³tkie nagrania (<5 min)**: UÅ¼ywaj `whisper-base` w przeglÄ…darce
2. **Åšrednie nagrania (5-30 min)**: Backend + `whisper-base`
3. **DÅ‚ugie nagrania (30-90 min)**: Backend + `whisper-tiny` lub Cloud API
4. **Bardzo dÅ‚ugie (>90 min)**: Cloud API (OpenAI, Assembly.AI)

## ğŸ” Troubleshooting

### Problem: Nadal wolno (>2 min na 10 min audio)

**SprawdÅº**:
1. Czy backend uÅ¼ywa lokalnych modeli?
   ```bash
   ls -lh public/models/Xenova/whisper-base/
   ```
2. Czy masz duÅ¼o wolnej pamiÄ™ci RAM?
   ```bash
   top -l 1 | grep PhysMem
   ```
3. Czy uÅ¼ywasz najnowszej wersji Node.js?
   ```bash
   node --version  # powinno byÄ‡ >=18
   ```

### Problem: Out of memory

**RozwiÄ…zanie**:
1. UÅ¼yj mniejszego modelu (`whisper-tiny`)
2. Zmniejsz `chunk_length_s` do 20
3. ZwiÄ™ksz limit Node.js:
   ```bash
   NODE_OPTIONS="--max-old-space-size=8192" npm start
   ```

## âœ¨ Rezultat

Po optymalizacjach:
- **10 minut audio**: ~50-90 sekund (~7-12x realtime) âœ…
- **OstrzeÅ¼enie "30 seconds"**: UsuniÄ™te âœ…
- **Stabilna wydajnoÅ›Ä‡**: Tak âœ…
- **Maksymalnie 1 minuta dla 60 min audio**: Nierealne âŒ

**NajbliÅ¼szy realny cel**: 
- 60 minut audio w 6-10 minut
- To jest Å›wietny wynik dla local processing! ğŸ‰
