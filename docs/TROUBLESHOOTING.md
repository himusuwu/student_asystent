# RozwiÄ…zywanie problemÃ³w z modelami Whisper

## âš ï¸ Problem: "Unsupported model type: whisper"

**NajczÄ™stszy problem!** Model nie jest w formacie ONNX wymaganym przez transformers.js.

### Szybkie rozwiÄ…zanie:
1. **UÅ¼yj modelu `base`** (masz go juÅ¼ w ONNX) - zmieÅ„ w Settings
2. **LUB uruchom backend** (zalecane dla dÅ‚ugich nagraÅ„): `cd server && npm start`

ğŸ“– SzczegÃ³Å‚y: [TROUBLESHOOTING_ONNX.md](./TROUBLESHOOTING_ONNX.md)

---

## Problem: "JSON.parse: unexpected character at line 1 column 1"

Ten bÅ‚Ä…d wystÄ™puje gdy aplikacja prÃ³buje zaÅ‚adowaÄ‡ model Whisper, ale nie moÅ¼e prawidÅ‚owo pobraÄ‡ plikÃ³w konfiguracyjnych.

### Przyczyny:

1. **PrÃ³ba pobrania z Hugging Face gdy brak poÅ‚Ä…czenia**: DomyÅ›lnie aplikacja prÃ³buje pobraÄ‡ modele z internetu (`modelSource: 'remote'`)
2. **NieprawidÅ‚owa walidacja odpowiedzi HTTP**: Zbyt restrykcyjna walidacja JSON moÅ¼e odrzucaÄ‡ prawidÅ‚owe odpowiedzi
3. **Nieznalezienie lokalnych modeli**: Modele lokalne istniejÄ… w `public/models/` ale nie sÄ… wykrywane

### RozwiÄ…zanie:

#### Opcja 1: Automatyczne wykrywanie (ZALECANE)
Od teraz aplikacja automatycznie wykrywa obecnoÅ›Ä‡ lokalnych modeli w folderze `public/models/` i uÅ¼ywa ich zamiast pobierania z internetu.

#### Opcja 2: RÄ™czna konfiguracja lokalnych modeli
W ustawieniach aplikacji ustaw:
- `modelSource`: `'local'`
- `localModelBase`: `'/models'`

#### Opcja 3: Wymuszenie pobierania z internetu
JeÅ›li chcesz pobraÄ‡ modele z Hugging Face:
- `modelSource`: `'remote'`
- Upewnij siÄ™, Å¼e masz poÅ‚Ä…czenie z internetem
- Opcjonalnie ustaw `hfMirror`: `'mirror'` aby uÅ¼yÄ‡ chiÅ„skiego mirrora

### Struktura plikÃ³w lokalnych modeli:

Modele powinny byÄ‡ umieszczone w:
```
public/models/Xenova/whisper-base/
â”œâ”€â”€ config.json
â”œâ”€â”€ generation_config.json
â”œâ”€â”€ preprocessor_config.json
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ vocab.json
â”œâ”€â”€ merges.txt
â””â”€â”€ onnx/
    â”œâ”€â”€ encoder_model.onnx
    â”œâ”€â”€ decoder_model_merged.onnx
    â””â”€â”€ ...
```

### Logi diagnostyczne:

W konsoli przeglÄ…darki szukaj logÃ³w z prefiksem `[AI]`:
- `[AI] Auto-detecting local models...` - sprawdzanie lokalnych modeli
- `[AI] Local model detected! Switching to local mode.` - znaleziono lokalne modele
- `[AI] Loading model ... â€¢ lokalnie` - Å‚adowanie z lokalnych plikÃ³w
- `[AI] Fetch: ...` - pokazuje wszystkie pobierane pliki

### Sprawdzenie czy lokalne modele sÄ… dostÄ™pne:

OtwÃ³rz konsolÄ™ przeglÄ…darki i wpisz:
```javascript
fetch('/models/Xenova/whisper-base/config.json')
  .then(r => r.json())
  .then(d => console.log('Model config:', d))
  .catch(e => console.error('BÅ‚Ä…d:', e))
```

JeÅ›li zobaczysz konfiguracjÄ™ modelu, lokalne pliki sÄ… dostÄ™pne.

### KolejnoÅ›Ä‡ Å‚adowania (fallback):

1. PrÃ³ba zaÅ‚adowania `Xenova/whisper-base` (zgodnie z ustawieniami)
2. JeÅ›li nie powiedzie siÄ™ - timeout po 60s i fallback do `Xenova/whisper-tiny`
3. PrÃ³ba WebGPU (jeÅ›li dostÄ™pne) z timeoutem 30s
4. Fallback do WASM

## Dodatkowe problemy:

### WebGPU timeout
JeÅ›li widzisz "WebGPU nieosiÄ…galne/zwÅ‚oka", to normalne - aplikacja automatycznie przeÅ‚Ä…cza siÄ™ na WASM.

### Wymuszenie WASM
W ustawieniach ustaw `forceWasm: true` aby pominÄ…Ä‡ WebGPU.

### Model za duÅ¼y
JeÅ›li model `base` jest za duÅ¼y lub wolno siÄ™ Å‚aduje, zmieÅ„ w ustawieniach:
- `whisperModel`: `'tiny'` (szybszy, mniej dokÅ‚adny)
- `whisperModel`: `'base'` (domyÅ›lny, dobry balans)
- `whisperModel`: `'small'` (wiÄ™kszy, dokÅ‚adniejszy, wolniejszy)
